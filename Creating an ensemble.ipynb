{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating an ensemble from saved pickled models\n",
    "This notebook shows an example of the code used to save the prediction scores from the pickled \".model\" files outputted by the main program, and how these are used to score an ensemble. The ensemble can also be plotted with the shown functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ML_scripts.ensemble_scoring as ens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the prediction scores and target values for a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data pickle to save target\n",
    "with open('data/load_data.pickle', 'rb') as outfile: \n",
    "    scores = pickle.load(outfile)['target']\n",
    "\n",
    "print('Loaded target:', scores.shape)\n",
    "unique, counts = np.unique(scores.y, return_counts=True)\n",
    "print('Class balance:', dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below example codes shows how to extract the predictions from model output files for the in this study selected random states. The actual output files are not included in this GitHub. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_states = [654, 114, 25, 759, 281, 250, 228, 142, 754, 104, 692, 758, 913, 558, 89, 604, 432, 32, 30, 95, 223, 238, 517, 616, 27, 574, 203, 733, 665, 718, 429, 225, 459, 603, 284, 828, 890, 6, 777, 825, 163, 714, 348, 159, 220, 980, 781, 344, 94, 389]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path of pickled model file\n",
    "path = 'Insert your path here'\n",
    "\n",
    "# Iterate over selected random states\n",
    "for rs in random_states: \n",
    "    # Set file name. The file name includes the labels given to the data saved in load_data.pickle. \n",
    "    file = 'rf.diet_16s_var250.rs'+str(rs)+'.model' # This is an example of a filename generated by the main program. \n",
    "    \n",
    "    # Open and extract model_data\n",
    "    with open(path+file, 'rb') as outfile: \n",
    "        model_data = list(pickle.load(outfile))\n",
    "        \n",
    "    (X_crop, y), (train, test), (fpr,tpr), ids_test, (preds, labels), thresholds, models = model_data\n",
    "\n",
    "    # Save filename to use as column header\n",
    "    col_name = '.'.join(file.split('.')[1:3])\n",
    "\n",
    "    # Save predictions as pandas dataframe\n",
    "    predictions = pd.DataFrame(data=preds, index=ids_test, columns=[col_name])\n",
    "    \n",
    "    # Concatenate with scores\n",
    "    scores = pd.concat([scores, predictions], axis=1, sort=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring an ensemble\n",
    "The ensemble scoring is made using three different methods:\n",
    "- Mean of prediction scores\n",
    "- Majority voting\n",
    "- Mean of confident prediction scores\n",
    "- Majority voting on confident prediction scores\n",
    "\n",
    "A function has been made to score predictions as an ensemble, when given a pandas dataframe containing the target and the prediction scores of selected models. This function is located in ```ML_scripts/ensemble_scoring.py``` and is called ```score_ensemble()```. The arguments are described below: \n",
    "- ```scores``` is a required argument which is a pandas dataframe containing a column with the target values and columns with prediction scores. \n",
    "- ```true_col``` is a string naming the dataframe column which contains the target values. Default is ```true_col='y'```. \n",
    "- ```drop``` names the columns to leave out if any. Default is ```drop=False```, meaning all columns are included in the ensemble scoring. \n",
    "- ```min_conf``` and ```max_conf``` set the interval of thresholds to try with step size ```step```, when scoring the ensemble with only the confidence prediction scores. Defaults are ```min_conf=0.6```, ```max_conf=0.99``` and ```step=0.05```. \n",
    "- ```threshold``` sets the threshold value for separating the classes. Default is ```threshold=0.5```. \n",
    "\n",
    "The output of this function is two pandas dataframes: \n",
    "- First dataframe contains the performance metrics as rows and scorings as columns. \n",
    "- Second dataframe contains the sample-wise ensemble predictions as each row with the different scoring methods as columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score the ensemble using scoring function\n",
    "ens_perf, ens_scores = ens.score_ensemble(scores=scores, true_col='y', min_conf=0.6, max_conf=0.9, step=0.05, verbose=False)\n",
    "\n",
    "# Save performances\n",
    "ens_perf.T.to_csv(path+'ensemble_perfs.csv', index_label='scoring')\n",
    "\n",
    "# Save ensemble predictions\n",
    "ens_scores.to_csv(path+'ensemble_scores.csv', index_label='samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print performances of different ensemble scoring methods\n",
    "ens_perf.T # This will print with metrics as columns and scorings as rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
